# GSAformer
The source code for **G**roup **S**parse **A**ttention Transformer (GSAformer) framework.

## Paper
**GSAformer: Group Sparse Attention Transformer for Functional Brain Network Analysis**

Lina Zhou, Xiao Jiang, Mengxue Pang, Lishan Qiao

## Datasets
We used the following datasets:

- ABIDE (Can be downloaded [here](http://fcon_1000.projects.nitrc.org/indi/abide/))
- REST-meta-MDD (Can be downloaded [here](http://rfmri.org/REST-meta-MDD))

## Dependencies
GSAformer needs the following dependencies:

- python 3.8.10
- torch == 1.9.0
- numpy == 1.21.1
- einops == 0.6.1
- scipy == 1.7.1
- sklearn == 0.0
- tqdm == 4.63.0
- pandas == 1.3.2
